<!DOCTYPE html>
<html>
  <head>
    <title>Table Annotation using Deep Learning</title>
    <link
      rel="stylesheet"
      href="https://webdatacommons.org/style.css"
      type="text/css"
      media="screen"
    />
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <style>
      .tar {
        text-align: right;
      }
      .rtable {
        float: right;
        padding-left: 10px;
      }
      .smalltable,
      .smalltable TD,
      .smalltable TH {
        font-size: 9pt;
      }
      .tab {
        overflow: hidden;
        border: 1px solid #ccc;
        background-color: #eaf3fa;
        clear: both;
        padding-left: 25px;
        width: 650px;
      }
      .tab button {
        background-color: inherit;
        float: left;
        border: none;
        outline: none;
        cursor: pointer;
        padding: 15px 60px;
        transition: 0.3s;
      }
      .tab button:hover {
        background-color: #ddd;
      }
      .tab button.active {
        background-color: #ccc;
      }
      .tabcontent {
        display: none;
        padding: 6px 12px;
        border-top: none;
        animation: fadeEffect 1s;
        width: 500px;
      }
      .table-wrapper {
        position: relative;
      }
      .table-scroll {
        height: 240px;
        overflow: auto;
        margin-top: -10px;
      }
      .show {
        display: block;
      }
      .no-show {
        display: none;
      }
      caption {
        caption-side: top;
        font-style: italic;
      }
      td[scope="mergedcol"] {
        text-align: center;
      }
      tr.bordered {
        border-bottom: 1px solid #000;
      }
      hr {
        width: 50%;
        margin: 20px 0;
        /* This leaves 10px margin on left and right. If only right margin is needed try margin-right: 10px; */
      }
      .tg {
        border-collapse: collapse;
        border-color: #ccc;
        border-spacing: 0;
      }
      .tg td {
        background-color: #fff;
        border-color: #ccc;
        border-style: solid;
        border-width: 1px;
        color: #333;
        font-family: Arial, sans-serif;
        font-size: 14px;
        overflow: hidden;
        padding: 10px 5px;
        word-break: normal;
      }
      .tg th {
        background-color: #f0f0f0;
        border-color: #ccc;
        border-style: solid;
        border-width: 1px;
        color: #333;
        font-family: Arial, sans-serif;
        font-size: 14px;
        font-weight: normal;
        overflow: hidden;
        padding: 10px 5px;
        word-break: normal;
      }
      .tg tr th {
        align-items: center;
      }

      .tg {
        vertical-align: top;
      }
      .tg .tg-lboi {
        border-color: inherit;
        text-align: left;
        vertical-align: middle;
      }
      .tg .tg-9wq8 {
        border-color: inherit;
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-ixdq {
        border-color: inherit;
        font-weight: bold;
        position: -webkit-sticky;
        position: sticky;
        text-align: center;
        top: -1px;
        vertical-align: middle;
        will-change: transform;
      }
      .tg .tg-mkpc {
        border-color: inherit;
        font-weight: bold;
        position: -webkit-sticky;
        position: sticky;
        text-align: left;
        top: -1px;
        vertical-align: middle;
        will-change: transform;
      }
      .tg .tg-d459 {
        background-color: #f9f9f9;
        border-color: inherit;
        text-align: left;
        vertical-align: middle;
      }
      .tg .tg-kyy7 {
        background-color: #f9f9f9;
        border-color: inherit;
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-h2b0 {
        background-color: #fff;
        border-color: inherit;
        color: #333;
        text-align: center;
        vertical-align: middle;
      }
      .tg-sort-header::-moz-selection {
        background: 0 0;
      }
      .tg-sort-header::selection {
        background: 0 0;
      }
      .tg-sort-header {
        cursor: pointer;
      }
      .tg-sort-header:after {
        content: "";
        float: right;
        margin-top: 7px;
        border-width: 0 5px 5px;
        border-style: solid;
        border-color: #404040 transparent;
        visibility: hidden;
      }
      .tg-sort-header:hover:after {
        visibility: visible;
      }
      .tg-sort-asc:after,
      .tg-sort-asc:hover:after,
      .tg-sort-desc:after {
        visibility: visible;
        opacity: 0.4;
      }
      .tg-sort-desc:after {
        border-bottom: none;
        border-width: 5px 5px 0;
      }
      @media screen and (max-width: 767px) {
        .tg {
          width: auto !important;
        }
        .tg col {
          width: auto !important;
        }
        .tg-wrap {
          overflow-x: auto;
          -webkit-overflow-scrolling: touch;
        }
      }
      .tg {
        border-collapse: collapse;
        border-color: #ccc;
        border-spacing: 0;
      }
      h3 {
        padding-bottom: 1rem;
      }
      .tg td {
        background-color: #fff;
        border-color: #ccc;
        border-style: solid;
        border-width: 1px;
        color: #333;
        font-family: Arial, sans-serif;
        font-size: 14px;
        overflow: hidden;
        padding: 10px 5px;
        word-break: normal;
      }
      .tg th {
        background-color: #f0f0f0;
        border-color: #ccc;
        border-style: solid;
        border-width: 1px;
        color: #333;
        font-family: Arial, sans-serif;
        font-size: 14px;
        font-weight: normal;
        overflow: hidden;
        padding: 10px 5px;
        word-break: normal;
      }
      .tg .tg-lboi {
        border-color: inherit;
        text-align: left;
        vertical-align: middle;
      }
      .tg .tg-9wq8 {
        border-color: inherit;
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-baqh {
        text-align: center;
        vertical-align: top;
      }
      .tg .tg-zyik {
        border-color: inherit;
        font-weight: bold;
        position: -webkit-sticky;
        position: sticky;
        text-align: center;
        top: -1px;
        vertical-align: top;
        will-change: transform;
      }
      .tg .tg-ixdq {
        border-color: inherit;
        font-weight: bold;
        position: -webkit-sticky;
        position: sticky;
        text-align: center;
        top: -1px;
        vertical-align: middle;
        will-change: transform;
      }
      .tg .tg-yy5h {
        background-color: #f0f0f0;
        border-color: inherit;
        font-weight: bold;
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-o939 {
        background-color: #f0f0f0;
        border-color: inherit;
        font-weight: bold;
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-ufyq {
        background-color: #f0f0f0;
        font-weight: bold;
        text-align: center;
        vertical-align: top;
      }
      .tg .tg-asv9 {
        background-color: #f0f0f0;
        border-color: inherit;
        font-weight: bold;
        text-align: center;
        vertical-align: top;
      }
      .tg .tg-d459 {
        background-color: #f9f9f9;
        border-color: inherit;
        text-align: left;
        vertical-align: middle;
      }
      .tg .tg-dzk6 {
        background-color: #f9f9f9;
        text-align: center;
        vertical-align: top;
      }
      .tg .tg-kyy7 {
        background-color: #f9f9f9;
        border-color: inherit;
        text-align: center;
        vertical-align: middle;
      }
      .tg-sort-header::-moz-selection {
        background: 0 0;
      }
      .tg-sort-header::selection {
        background: 0 0;
      }
      .tg-sort-header {
        cursor: pointer;
      }
      .tg-sort-header:after {
        content: "";
        float: right;
        margin-top: 7px;
        border-width: 0 5px 5px;
        border-style: solid;
        border-color: #404040 transparent;
        visibility: hidden;
      }
      .tg-sort-header:hover:after {
        visibility: visible;
      }
      .tg-sort-asc:after,
      .tg-sort-asc:hover:after,
      .tg-sort-desc:after {
        visibility: visible;
        opacity: 0.4;
      }
      .tg-sort-desc:after {
        border-bottom: none;
        border-width: 5px 5px 0;
      }
      @media screen and (max-width: 767px) {
        .tg {
          width: auto !important;
        }
        .tg col {
          width: auto !important;
        }
        .tg-wrap {
          overflow-x: auto;
          -webkit-overflow-scrolling: touch;
        }
      }
      h2 {
        padding-bottom: 1rem;
      }
      .tg {
        border-collapse: collapse;
        border-color: #ccc;
        border-spacing: 0;
        display: inline-block;
        margin-right: 50px;
      }
      .tg td {
        background-color: #fff;
        border-color: #ccc;
        border-style: solid;
        border-width: 1px;
        color: #333;
        font-family: Arial, sans-serif;
        font-size: 14px;
        overflow: hidden;
        padding: 10px 5px;
        word-break: normal;
      }
      .tg th {
        background-color: #f0f0f0;
        border-color: #ccc;
        border-style: solid;
        border-width: 1px;
        color: #333;
        font-family: Arial, sans-serif;
        font-size: 14px;
        font-weight: normal;
        overflow: hidden;
        padding: 10px 5px;
        word-break: normal;
      }
      .tg .tg-lboi {
        border-color: inherit;
        text-align: left;
        vertical-align: middle;
      }
      .tg .tg-pl4i {
        background-color: #f0f0f0;
        font-weight: bold;
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-j1i3 {
        border-color: inherit;
        position: -webkit-sticky;
        position: sticky;
        text-align: left;
        top: -1px;
        vertical-align: top;
        will-change: transform;
      }
      .tg .tg-9wq8 {
        border-color: inherit;
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-ixdq {
        border-color: inherit;
        font-weight: bold;
        position: -webkit-sticky;
        position: sticky;
        text-align: center;
        top: -1px;
        vertical-align: middle;
        will-change: transform;
      }
      .tg .tg-yy5h {
        background-color: #f0f0f0;
        border-color: inherit;
        font-weight: bold;
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-o939 {
        background-color: #f0f0f0;
        border-color: inherit;
        font-weight: bold;
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-45e1 {
        background-color: #f0f0f0;
        border-color: inherit;
        font-weight: bold;
        text-align: left;
        vertical-align: middle;
      }
      .tg .tg-nrix {
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-d459 {
        background-color: #f9f9f9;
        border-color: inherit;
        text-align: left;
        vertical-align: middle;
      }
      .tg .tg-kyy7 {
        background-color: #f9f9f9;
        border-color: inherit;
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-57iy {
        background-color: #f9f9f9;
        text-align: center;
        vertical-align: middle;
      }
      .tg .tg-zkss {
        background-color: #fff;
        border-color: inherit;
        color: #333;
        text-align: center;
        vertical-align: top;
      }
      .tg .tg-p91v {
        background-color: #ff0;
        border-color: inherit;
        color: #333;
        font-weight: bold;
        text-align: center;
        vertical-align: top;
      }
      .tg .tg-c3ow {
        border-color: inherit;
        text-align: center;
        vertical-align: top;
      }
      .tg .tg-syo5 {
        background-color: #f0f0f0;
        border-color: inherit;
        color: #333;
        font-weight: bold;
        text-align: center;
        vertical-align: top;
      }
      .tg .tg-h2b0 {
        background-color: #fff;
        border-color: inherit;
        color: #333;
        text-align: center;
        vertical-align: middle;
      }
      .tg-sort-header::-moz-selection {
        background: 0 0;
      }
      .tg-sort-header::selection {
        background: 0 0;
      }
      .tg-sort-header {
        cursor: pointer;
      }
      .tg-sort-header:after {
        content: "";
        float: right;
        margin-top: 7px;
        border-width: 0 5px 5px;
        border-style: solid;
        border-color: #404040 transparent;
        visibility: hidden;
      }
      .tg-sort-header:hover:after {
        visibility: visible;
      }
      .tg-sort-asc:after,
      .tg-sort-asc:hover:after,
      .tg-sort-desc:after {
        visibility: visible;
        opacity: 0.4;
      }
      .tg-sort-desc:after {
        border-bottom: none;
        border-width: 5px 5px 0;
      }
      @media screen and (max-width: 767px) {
        .tg {
          width: auto !important;
        }
        .tg col {
          width: auto !important;
        }
        .tg-wrap {
          overflow-x: auto;
          -webkit-overflow-scrolling: touch;
        }
      }
      @keyframes fadeEffect {
        from {
          opacity: 0;
        }
        to {
          opacity: 1;
        }
      }
      .center {
        display: block;
        margin-left: auto;
        margin-right: auto;
        width: 30%;
      }
      figure figcaption {
        text-align: center;
      }
    </style>
    <script
      type="text/javascript"
      src="http://ajax.googleapis.com/ajax/libs/jquery/1.7.1/jquery.min.js"
    ></script>
    <script type="text/javascript" src="../../jquery.toc.min.js"></script>
    <script type="text/javascript">
      var _gaq = _gaq || [];
      _gaq.push(["_setAccount", "UA-30248817-1"]);
      _gaq.push(["_trackPageview"]);

      (function () {
        var ga = document.createElement("script");
        ga.type = "text/javascript";
        ga.async = true;
        ga.src =
          ("https:" == document.location.protocol
            ? "https://ssl"
            : "http://www") + ".google-analytics.com/ga.js";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(ga, s);
      })();
    </script>
    <script charset="utf-8">
      var TGSort =
        window.TGSort ||
        (function (n) {
          "use strict";
          function r(n) {
            return n ? n.length : 0;
          }
          function t(n, t, e, o = 0) {
            for (e = r(n); o < e; ++o) t(n[o], o);
          }
          function e(n) {
            return n.split("").reverse().join("");
          }
          function o(n) {
            var e = n[0];
            return (
              t(n, function (n) {
                for (; !n.startsWith(e); ) e = e.substring(0, r(e) - 1);
              }),
              r(e)
            );
          }
          function u(n, r, e = []) {
            return (
              t(n, function (n) {
                r(n) && e.push(n);
              }),
              e
            );
          }
          var a = parseFloat;
          function i(n, r) {
            return function (t) {
              var e = "";
              return (
                t.replace(n, function (n, t, o) {
                  return (e = t.replace(r, "") + "." + (o || "").substring(1));
                }),
                a(e)
              );
            };
          }
          var s = i(/^(?:\s*)([+-]?(?:\d+)(?:,\d{3})*)(\.\d*)?$/g, /,/g),
            c = i(/^(?:\s*)([+-]?(?:\d+)(?:\.\d{3})*)(,\d*)?$/g, /\./g);
          function f(n) {
            var t = a(n);
            return !isNaN(t) && r("" + t) + 1 >= r(n) ? t : NaN;
          }
          function d(n) {
            var e = [],
              o = n;
            return (
              t([f, s, c], function (u) {
                var a = [],
                  i = [];
                t(n, function (n, r) {
                  (r = u(n)), a.push(r), r || i.push(n);
                }),
                  r(i) < r(o) && ((o = i), (e = a));
              }),
              r(
                u(o, function (n) {
                  return n == o[0];
                })
              ) == r(o)
                ? e
                : []
            );
          }
          function v(n) {
            if ("TABLE" == n.nodeName) {
              for (
                var a = (function (r) {
                    var e,
                      o,
                      u = [],
                      a = [];
                    return (
                      (function n(r, e) {
                        e(r),
                          t(r.childNodes, function (r) {
                            n(r, e);
                          });
                      })(n, function (n) {
                        "TR" == (o = n.nodeName)
                          ? ((e = []), u.push(e), a.push(n))
                          : ("TD" != o && "TH" != o) || e.push(n);
                      }),
                      [u, a]
                    );
                  })(),
                  i = a[0],
                  s = a[1],
                  c = r(i),
                  f = c > 1 && r(i[0]) < r(i[1]) ? 1 : 0,
                  v = f + 1,
                  p = i[f],
                  h = r(p),
                  l = [],
                  g = [],
                  N = [],
                  m = v;
                m < c;
                ++m
              ) {
                for (var T = 0; T < h; ++T) {
                  r(g) < h && g.push([]);
                  var C = i[m][T],
                    L = C.textContent || C.innerText || "";
                  g[T].push(L.trim());
                }
                N.push(m - v);
              }
              t(p, function (n, t) {
                l[t] = 0;
                var a = n.classList;
                a.add("tg-sort-header"),
                  n.addEventListener("click", function () {
                    var n = l[t];
                    !(function () {
                      for (var n = 0; n < h; ++n) {
                        var r = p[n].classList;
                        r.remove("tg-sort-asc"),
                          r.remove("tg-sort-desc"),
                          (l[n] = 0);
                      }
                    })(),
                      (n = 1 == n ? -1 : +!n) &&
                        a.add(n > 0 ? "tg-sort-asc" : "tg-sort-desc"),
                      (l[t] = n);
                    var i,
                      f = g[t],
                      m = function (r, t) {
                        return n * f[r].localeCompare(f[t]) || n * (r - t);
                      },
                      T = (function (n) {
                        var t = d(n);
                        if (!r(t)) {
                          var u = o(n),
                            a = o(n.map(e));
                          t = d(
                            n.map(function (n) {
                              return n.substring(u, r(n) - a);
                            })
                          );
                        }
                        return t;
                      })(f);
                    (r(T) ||
                      r((T = r(u((i = f.map(Date.parse)), isNaN)) ? [] : i))) &&
                      (m = function (r, t) {
                        var e = T[r],
                          o = T[t],
                          u = isNaN(e),
                          a = isNaN(o);
                        return u && a
                          ? 0
                          : u
                          ? -n
                          : a
                          ? n
                          : e > o
                          ? n
                          : e < o
                          ? -n
                          : n * (r - t);
                      });
                    var C,
                      L = N.slice();
                    L.sort(m);
                    for (var E = v; E < c; ++E)
                      (C = s[E].parentNode).removeChild(s[E]);
                    for (E = v; E < c; ++E) C.appendChild(s[v + L[E - v]]);
                  });
              });
            }
          }
          n.addEventListener("DOMContentLoaded", function () {
            for (var t = n.getElementsByClassName("tg"), e = 0; e < r(t); ++e)
              try {
                v(t[e]);
              } catch (n) {}
          });
        })(document);
    </script>
    <!-- MathJax: cdn to display latex equations -->
    <script
      type="text/javascript"
      async=""
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"
    ></script>
  </head>
  <body>
    <div id="logo" style="text-align: right; background-color: white">
      &nbsp;&nbsp;<a href="http://dws.informatik.uni-mannheim.de"
        ><img src="images/ma-logo.gif" alt="University of Mannheim - Logo"
      /></a>
    </div>
    <div id="header">
      <h1 style="font-size: 250%">Table Annotation using Deep Learning</h1>
    </div>
    <div id="authors">
      <a>Christian Bizer</a><br />
      <a>Chun-Yi Chen</a><br />
      <a>I-Chen Hsieh</a><br />
      <a>Keti Korini</a><br />
      <a>Munir Abobaker</a><br />
      <a>Reng Chiz Der</a><br />
    </div>

    <div id="content">
      <p>
        This webpage engages with the experiements and results of a six month
        student team project on the topic of "Table Annotation using Deep
        Learning" at the School of Business Informatics and Mathematics of the
        University of Mannheim under the supervision of Keti Korini and
        Christian Bizer.
      </p>
      <p>
        We have conducted a set of experiments around the use of transformer
        language models for table annotation, based on
        <a href="https://webdatacommons.org/structureddata/sotab/"
          >WDC Schema.org Table Annotation Benchmark (SOTAB)</a
        >[<a href="#toc9">1</a>]. There are two multi-class classification
        tasks:
        <a href="https://paperswithcode.com/task/column-type-annotation"
          >Column Type Annotation (CTA)</a
        >
        and
        <a href="https://paperswithcode.com/task/columns-property-annotation"
          >Columns Property Annotation (CPA)</a
        >. CTA involves predicting the column type, while CPA involves
        predicting the column properties or relations. All of our experiments
        and code are available in our
        <a
          href="https://github.com/wbsg-uni-mannheim-students/table-annotation-using-deep-learning"
          >GitHub repository.</a
        >
      </p>

      <p>
        This work is organized as follows. Firstly, in Chapter 1, we will
        introduce and motivate the task of table annotation. Furthermore, in
        Chapter 2, we will provide an overview of the table annotation tasks. Subsequently, in Chapter 3, we will present the
        related work including, Transformer model. Moving on to Chapter 4, we will describe the models,
        preprocessing steps, and serialization approaches. Additionally, in
        Chapter 5, we will describe the experiment setup. Then, in Chapter 6, we
        will delve into the experimental results and error analysis. Finally, in
        Chapters 7 and 8, we will discuss the results and conclude the work,
        respectively.
      </p>
      <h2>Contents</h2>
      <ul>
        <li class="toc-h2 toc-active">
          <a href="#toc1"> 1. Introduction</a>
        </li>
        <li class="toc-h2 toc-active">
          <a href="#toc2"> 2. Theoretical Background</a>
          <ul>
            <li>
              <a href="#toc2.1">2.1 CTA</a>
            </li>
            <li>
              <a href="#toc2.2">2.2 CPA</a>
            </li>
          </ul>
        </li>
        <li class="toc-h2 toc-active">
          <a href="#toc3"> 3. Related Work</a>
          <ul>
            <li>
              <a href="#toc3.1">3.1 Transformer</a>
            </li>
          </ul>
        </li>
        <li class="toc-h2 toc-active">
          <a href="#toc4"> 4. Model </a>
          <ul>
            <li>
              <a href="#toc4.1">4.1 Preprocessing and Augmentation</a>
            </li>
            <li>
              <a href="#toc4.2">4.2 Serialization</a>
            </li>
            <li>
              <a href="#toc4.3">4.3 Further Models</a>
            </li>
          </ul>
        </li>
        <li class="toc-h2 toc-active">
          <a href="#toc5"> 5. Experiment </a>
        </li>
        <li class="toc-h2 toc-active">
          <a href="#toc6"> 6. Experimental Results and Error Analysis </a>
        </li>
        <li class="toc-h2 toc-active">
          <a href="#toc7"> 7. Conclusion </a>
        </li>
        <li class="toc-h2 toc-active">
          <a href="#toc8"> 8. References </a>
        </li>
      </ul>
      <span id="toc1"></span>
      <h2>1. Introduction</h2>
      <p>
        Table annotation is the process of adding descriptive labels to tables
        in a large dataset using concepts from a knowledge graph or shared
        vocabulary. This process is crucial for effective data search and
        integration, especially since the web contains millions of high-quality
        tables available on websites and public data portals such as Wikipedia.
        However, to utilize these tables, we need to understand their structure
        and schema, which can be challenging due to their heterogeneous or
        unknown headers and content. The objective of this project is to address
        the aforementioned challenges by proficiently utilizing diverse deep
        learning methods for both Column Type Annotation and Columns Property
        Annotation tasks.
      </p>

      <span id="toc2"></span>
      <h2>2. Theoretical Background</h2>
      <p>
        This Chapter provides an overview of the theoretical underpinnings,
        frameworks as well as specific information relevant to follow our work.
        For this reason, we start by introducing the main tasks we are trying to
        solve.
      </p>
      <span id="toc2.1"></span>

      <h3>2.1 Column Type Annotation (CTA)</h3>
      <p>
        Column Type Annotation (CTA) is a critical task in data integration and
        knowledge discovery that involves assigning labels to each column in a
        table based on the types of entities it contains such as
        <b
          >"hotel/name", "streetAddress","addressLocality", "Country", and
          "currency"
        </b>
        as shown in <a href="#toc2.1.Fig">Figure 1</a>. While data types provide
        basic information about the type of data stored in a column, entity
        types capture domain-specific semantics that convey more meaning. For
        instance, labeling a column with <b>"hotel/name"</b> rather than just
        <b>"String" </b> provides valuable information about the specific type
        of data stored in that column, which is crucial for downstream tasks
        such as data analysis and retrieval [<a href="#toc8">1</a>,<a
          href="#toc14"
          >4</a
        >].
      </p>

      <p>
        An example of CTA: An e-commerce website may have a table of products
        with columns such as "product name", "description", "price", "category",
        and "brand". By annotating the columns with entity types such as
        "product name", "brand", and "category", a machine learning model can
        better understand the semantic meaning of the data, and accurately
        categorize products into appropriate categories, recommend related
        products, and provide a more personalized shopping experience to the
        user.
      </p>

      <p>
        CTA can be approached as either
        <a href="https://paperswithcode.com/task/column-type-annotation/">
          a multi-class or a multi-label classification</a
        >
        problem. In multi-class, each column is annotated with only one label
        representing its type, while in multi-label, each column is annotated
        with multiple labels.
      </p>

      <span id="toc2.2"></span>
      <h3>2.2 Columns Property Annotation (CPA)</h3>
      <p>
        CPA is a web data integration task and it plays a crucial role in
        ensuring data quality control and schema matching[<a href="#toc17">7</a
        >]. It aims to identify relationships between different columns in a
        table. It can infer relationships that might not be immediately obvious,
        as illustrated in <a href="#toc2.1.Fig">Figure 1</a>. Here, CPA can help
        to infer that the <b>"address" </b>column refers to the hotel's location.
      </p>

      <p>
        One common way to tackle CPA is to view it as a
        <a href="https://paperswithcode.com/task/columns-property-annotation/">
          multi-class classification</a
        >
        task, and it is also known as column relation annotation or relation
        extraction in various works.
      </p>

      <span id="toc2.1.Fig"></span>
      <figure>
        <img
          src="images/table_CTA_CPA.jpg"
          alt="Table Annotation Example"
          class="center"
        />
        <figcaption class="center">
          <b><a id="Fig1"></a>Figure 1:</b> Example of table annotation. The CTA
          labels are placed on the top of the columns, while the CPA labels are
          placed between the main column (leftmost column) and another column
          [<a href="#toc8">1</a>]
        </figcaption>
      </figure>

      <span id="toc3"></span>
      <h2>3. Related Work</h2>
      <span id="toc3.1"></span>
      <p>
        Chapter 3 provides an overview of relevant literature on table
        annotation tasks and a Transformer-based language model, which is
        currently the state-of-the-art approach for these tasks.
      </p>
      <h3>3.1 TURL</h3>
      <p>
        The paper [<a href="#toc12">4</a>] provides a cornerstone for table
        representation through the introduction of a framework for table
        understanding called TURL. TURL achieves this by utilizing
        representation learning to learn contextualized representations on
        relational tables. TURL's unsupervised pre-training on a vast web table
        corpus derived from WikiTable facilitates its application in various
        downstream tasks, requiring only minimal task-specific modifications.
        For example, the TURL framework can be used to infer valuable
        information about tables such as column types and the relationships
        between columns (CTA and CPA).
      </p>

      <span id="toc3.2"></span>
      <h3>3.2 TUTA</h3>
      <p>
        TUTA, as introduced in [<a href="#toc16">8</a>], represents the first
        transformer-based model for the CTA and CPA tasks. Notably, TUTA
        demonstrates the importance of incorporating structure-aware mechanisms
        for table representation tasks. It captures the spatial and hierarchical
        information of tables through a tree-based attention and position
        mechanism. TUTA inspired us to incorporate similar preprocessing and
        structural-based approaches in our work.
      </p>

      <span id="toc3.3"></span>
      <h3>3.3 DODUO</h3>
      DODUO, as described in [<a href="#toc15">7</a>], is the ccurent
      state-of-the-art approach for the CTA and CPA tasks. This approach
      utilizes a Transformer-based language model and takes the entire table as
      input to predict column types and relationships between columns. What sets
      DODUO apart is its ability to annotate table columns using only the
      information contained in the table itself, without the need for external
      knowledge or context.
      <p></p>
      <span id="toc3.4"></span>
      <h3>3.4 Transformer</h3>
      <p>
        Transformers are a type of neural network architecture that has become
        widely used in natural language processing and other machine learning
        applications. They were first introduced in 2017 by Vaswani et al [<a
          href="#toc15"
          >5</a
        >]. and have since become one of the most popular deep-learning models.
        Transformers are based on the concept of self-attention, which allows
        the model to focus on different parts of the input sequence at each
        step.
      </p>

      <p>
        The key innovation of transformers is self-attention, a mechanism that
        allows the model to selectively focus on different parts of the input
        sequence. Self-attention works by computing a weighted sum of the input
        sequence at each position, where the weights are determined by a
        similarity function between the current position and all other
        positions. The output of the self-attention layer is a sequence of
        weighted sums, which can then be fed into subsequent layers of the
        network. The attention function is formalized as:
      </p>
      <p>
        <span class="math display"
          >\[Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V\]</span
        >
      </p>
      <p>
        where Q, K, and V are the query, key, and value vectors, respectively.
      </p>
      <p>
        A Transformer-based language model is ideal for the tasks due to its language understanding capabilities and
        Transformer's attention mechanism that captures contextualized column
        representations.
      </p>
      <span id="toc4"></span>
      <h2>4. Model</h2>
      <p>
        A Transformer-based language models expect token (text) sequences as
        inputs. This translates to representing tables in text sequences,
        formally known as table serialization, for the tasks of CTA and CPA.
        Single-column serialization is an intuitive solution that concatenates
        column values into a sequence to feed into the language model.
        Specifically, as defined by Suhara et al. [<a href="#toc15">7</a>], for
        column <i>C</i> with column values <i>v<sub>1</sub>,...,v<sub>m</sub></i
        >, the serialized sequence is [<a href="#toc15">7</a>]:
        <span class="math display"
          >\[serialize_{single}(C)::= [CLS]\;v_1\;...\;v_m\;[SEP]\]</span
        >
      </p>
      <p>
        Table serialization conveniently translates the CTA and CPA tasks into
        sequence classification and sequence-pair classification task
        respectively. However, the major drawback of single-column serialization
        is that it treats each column in a table as an independent sequence,
        neglecting the crucial table context that defines a real-world entity
        for a relational table. Previous works [<a href="#toc15">7,</a
        ><a href="#toc17">9,</a><a href="#toc18">10,</a><a href="#toc19">11</a>]
        have highlighted the importance of table context for the CTA task. At
        the other end of the spectrum for table serialization is DODUO, which
        represents a table as an aggregation of contextual information from all
        column values. Our work's main focus and contributions include
        experimenting with various serialization strategies, preprocessing
        techniques, and augmentation methods to account for table context.
      </p>

      <span id="toc4.1"></span>
      <h3>4.1 Preprocessing and Augmentation</h3>
      <p>
        To accommodate the token limit of 512 tokens for BERT-like language
        models, we trim cell values for longer textual data to fit more cells
        from a table. Following Wang et al. [<a href="#toc16">8</a>]'s empirical
        studies, we retain at most 8 tokens from a cell. This is because long
        textual strings often introduce noise and disrupt the structure of a
        table input. Additionally, we experiment with different threshold cell
        lengths, i.e., <em>median</em> and <em>mean</em> cell length computed
        per column basis. The rational being a long textual column contains
        strings of different length.
      </p>
      <p>
        To enhance our data processing, we perform data augmentation (DA) at
        both the cell and table level during the earlier stages of our workflow.
        Specifically, we apply standard textual DA techniques, such as word
        swapping, word replacement, word deletion, and column cell value
        shuffling, at the cell level. At the table level, we perform random cell
        deletion and column cell shuffling.
      </p>

      <span id="toc4.2"></span>
      <h3>4.2 Serialization</h3>
      <p>
        <b>(i) Neighboring Column:</b> The
        <em>Neighboring Column Serialization</em> technique utilizes adjacent
        columns as local context in a relational table. Previous research by
        SATO [<a href="#toc19">11</a>] demonstrated that incorporating local
        context aids in resolving semantic type ambiguities in single-column
        predictions. To accomplish this, their approach incorporates the
        predicted semantic types of immediately adjacent columns as local
        context for a column prediction model of neural network. For our
        approach, we utilize neighboring columns of varying window sizes along
        with the target column in the CTA task. Furthermore, for the CPA task,
        we incorporate neighboring columns for both the main and target columns.
      </p>
      <p>
        To build on the Neighboring Column Serialization approach, we introduce
        a more complex variation called
        <em>Neighboring Column with Summary Serialization</em>. This approach
        leverages results from exploratory data analysis (EDA) to extract
        relevant column value data. We use the pandas-profiling library [<a
          href="#toc20"
          >12</a
        >] to infer column data types and analyzes text and context using common
        statistical metrics such as mean, maximum, and minimum text length. We
        prepend the statistical results to the data for each column, providing a
        syntax summary for lengthy columns/tables as part of the local context.
      </p>
      <p>
        However, for the CPA task, including the main column and its local
        context in conjunction with the Neighboring Column Serialization
        approach can lead to redundancy. Therefore, we transfer the Neighboring
        Column Serialization technique from the CTA task to the CPA task,
        without including the main column, which we refer to as the
        <em>No-Main Neighboring Column Serialization</em>.
      </p>

      <span id="toc4.2.1.Fig"></span>
      <figure>
        <img
          src="./images/Neighbor.gif"
          alt="Neighbor illustration GIF"
          style="width: 550px; height: 330px"
          class="center"
        />
        <figcaption class="center">
          <b><a id="Fig2"></a>Figure 2:</b> Neighboring Column Serialization
        </figcaption>
      </figure>

      <p>
        <b>(ii) TaBERT:</b> In <em>TaBERT Serialization</em>, our goal is to
        capture the relationship between the target column and the context
        columns by inputting the context data row-wise. To achieve this, we
        follow the approach proposed by TUTA [<a href="#toc16">8</a>], where we
        prepend a data type token to each cell. This row serialization approach
        helps the Transformer's attention mechanism better capture the table
        structure while maintaining constant intervals for each column.
        Moreover, by including data types, the language model can learn the
        relationships between the cells of the target column and the prediction
        label. For instance, a URL data for company, label, or hotel photos may
        indicate a target label of "Logo".
      </p>
      <p>
        To reduce the number of additional tokens required for inserting data
        types in each cell, we introduce <em>Column-TaBERT Serialization</em>,
        which infers the data type for each column by majority count and
        includes the data types for each column only once. For the CTA task, the
        resulting serialization is illustrated in
        <a href="#toc4.2.2.Fig">Figure 3</a> or:
        <span class="math display"
          >\[serialize_{col\_tabert}(C)::=
          [CLS]\;target\_col\_type\;target\_col\_data\;[SEP]\;context\_col\_1\_type\;context\_col\_2\_type\;...\;[SEP]\;row\_data\;[SEP]\]</span
        >
      </p>

      <span id="toc4.2.2.Fig"></span>
      <figure>
        <img
          src="./images/TaBERT.gif"
          alt="Neighbor illustration GIF"
          style="width: 550px; height: 330px"
          class="center"
        />
        <figcaption class="center">
          <b><a id="Fig3"></a>Figure 3:</b> TaBERT Serialization
        </figcaption>
      </figure>

      <span id="toc4.3"></span>
      <h3>4.3 Further Models</h3>
      <p>
        We further explore different experimental models for the CPA task in
        various iterations.
      </p>
      <p>
        <b>(i) Subtable Model:</b> According to the statistics provided by SOTAB
        Benchmark [<a href="#toc9">1</a>], the CPA task involves 48,379 tables
        with a total of 174,998 columns. Notably, the tables have a median of 42
        rows and 8 columns. To increase the diversity of the training data and
        incorporate more parts of each table, we divide each table into
        subtables consisting of a maximum of 20 rows per subtable and up to 5
        subtables per table. As a result, our approach now encompasses a total
        of 391,115 columns.
      </p>
      <p>
        <b>(ii) 2-Step Model:</b> To improve the accuracy of our predictions, we
        adopt a 2-step model that leverages the 17 schema.org labels associated
        with each table. Specifically, we first predict the schema type of a
        table using a model trained on the SOTAB Benchmark [<a href="#toc9">1</a
        >] training data. This allows us to restrict our predictions to only
        relevant labels for each column. For example, if a column is identified
        as "Book", it will not be predicted as "MusicRecording/Name" for a CTA
        task. Next, we train submodels for each schema type to predict the final
        label for each column. To make predictions on test data, we first
        predict the schema type and then use the corresponding submodel to
        predict the final label for each column.
      </p>
      <p>
        <b>(ii) LongFormer:</b> Transformer-based models suffer from a
        limitation when it comes to processing long sequences. The
        self-attention operation in transformers scales quadratically with the
        sequence length, which restricts the ability to process long texts. This
        is a challenge in table annotation where long texts need to be
        processed. While models such as BERT or RoBERTa [<a href="#toc22">14</a
        >, <a href="#toc23">15</a>] are limited to a sequence length of 512, [<a
          href="#toc21"
          >13</a
        >] proposes Longformer, which has a linear attention mechanism that can
        process longer sequences length. The maximum length is constrained by the memory of
        GPU.
      </p>

      <span id="toc5"></span>
      <h2>5. Experiment</h2>
      <p>
        To conduct our experiments, we utilized computing resources from the
        University of Mannheim (dws-server) and bwHPC servers provided by the
        state of Baden-WÃ¼rttemberg.
      </p>

      <span id="toc5.1"></span>
      <h3>5.1 Dataset</h3>
      <p>
        We evaluated our solutions primarily on the
        <a href="https://webdatacommons.org/structureddata/sotab/"
          >WDC Schema.org Table Annotation Benchmark (SOTAB)</a
        >[<a href="#toc9">1</a>] benchmark dataset. To ensure the
        generalizability of our approach, we perform transfer learning to the
        <a href="https://github.com/sunlab-osu/TURL/"
          >WikiTables dataset by TURL</a
        >[<a href="#toc12">3</a>]. The SOTAB benchmark is a collection of tables
        extracted from the Schema.org Table Corpus, which is maintained by the
        Data and Web Science Research Group at the University of Mannheim. The
        corpus comprises over 4.2 million web relational tables covering 43
        schema.org classes. The dataset defines both CTA and CPA labels for
        tables from 17 schema.org classes/domains. For the CTA task, the SOTAB
        dataset provides annotations for 162,351 columns from 59,548 tables,
        with a label space of 91 type labels. For the CPA task, it provides
        annotations for 174,998 column pairs from 48,379 tables, with a label
        space of 176 property labels. We used the provided train/valid/test
        splits for both tasks.
      </p>
      <p>
        The WikiTables dataset [<a href="#toc12">3</a>] is a collection of
        tables extracted from the WikiTable corpus, which contains over 1.54
        million tables extracted from Wikipedia pages. The dataset defines both
        CTA and CPA labels. For the CTA task, the dataset provides annotations
        of 628,254 columns from 397,098 tables, with a label space of 255 type
        labels for training, and 13,025 (13,391) columns from 4,764 (4,844)
        tables for test and validation, respectively. For the CPA task, it
        provides annotations of 62,954 column pairs from 52,943 tables, with a
        label space of 121 relation labels for traning, and 2,072 (2,175) column
        pairs from 1,467 (1,560) tables for test (validation).
      </p>

      <span id="toc5.2"></span>
      <h3>5.2 Experimental Settings</h3>
      <p>
        For our experiments on both the SOTAB benchmark and WikiTables dataset,
        we trained a RoBERTa model with default settings: 30 epochs, 3 runs
        (with seed 0-2), and a batch size of 32. The initial learning rate was
        set to 5e-5, and we used a linear decay scheduler with no warmup. We set
        a maximum token length of 512, used a window size of 5, and a standard
        MP ratio of 0.5 for relevant serializations. We identify single-column
        serialization as the baseline configuration. For the SOTAB benchmark, we
        formulated the task as a multi-label prediction problem and used Cross
        Entropy loss. For the WikiTable dataset, we formulated the task as a
        multi-class prediction problem and used Binary Cross Entropy loss. We
        evaluated the performance of our models using micro F1 scores for both
        datasets.
      </p>

      <span id="toc5.3"></span>
      <h3>5.3 Experiments for SOTAB benchmark</h3>
      <p>
        For the SOTAB benchmark, we conducted extensive experiments on
        serialization for both CTA and CPA tasks. Specifically, we tested
        different variants of Neighboring Column Serialization and TaBERT
        Serialization. For CPA, we also performed No-Main Neighboring Column
        Serialization, which treats a CPA task as a CTA task.
      </p>
      <p>
        In order to explore more possibilities for the challenging CPA task, we
        further investigated Subtable, 2-Step, and Longformer models. For the
        Subtable Model, we trained a BERT model for 30 epochs with a batch size
        of 16 and a maximum token length of 512 tokens. We utilized a
        Neighboring Column Serialization of window size 2 for this model. For
        the 2-Step model, we used default parameter settings, including a
        RoBERTa model trained for 30 epochs. For the Longformer model, we used
        single-column serialization with a batch size of 8 and maximum length of
        1000.
      </p>
      <p>
        We conducted ablation studies for both CTA and CPA tasks to investigate
        the impact of different window sizes for Neighboring Column
        Serializations. We also experimented with different preprocessing
        methods, such as TUTA, median, and mean preprocessing for each promising
        serialization. Additionally, we varied the proportions of the target
        column and local context (MP - Main Percentange Ratio) to assess the
        effect of context weight on different serializations, experimenting with
        MP Ratios of 0.2, 0.5, and 0.8, respectively. Finally, in the early
        stages of our workflow, we investigated the performance of augmentation
        strategies on single-column serialization for the CPA task.
      </p>

      <span id="toc5.4"></span>
      <h3>5.4 Experiments for WikiTables dataset</h3>
      <p>
        To test the generalizability of our findings for the SOTAB benchmark, we
        transferred the serialization methods to the WikiTables dataset. For the
        CTA task, we used only Column-TaBERT Serialization due to computational
        limitations resulting from the dataset's size. For the CPA task, we
        experimented with different serializations, including TaBERT,
        Column-TaBERT, and No-Main Neighboring Column Serializations. We
        utilized the default experimental parameters as described and following
        Suhara et al. [<a href="#toc15">7</a>], we trained the model for 15
        epochs.
      </p>

      <span id="toc6"></span>
      <h2>6. Experimental Results and Error Analysis</h2>

      <span id="toc6.1"></span>
      <h3>6.1 Main Results</h3>

      <div style="text-align: center" class="tg-wrap">
        <table class="tg tg-top">
          <thead>
            <caption>
              Table 1a: CTA Experiment results
            </caption>
            <tr>
              <th class="tg-mkpc"></th>
              <th class="tg-mkpc" colspan="3">
                <span style="background-color: #f0f0f0">MP Ratio</span>
              </th>
            </tr>
          </thead>
          <tfoot>
            <tr>
              <td colspan="4">
                <sup>*</sup>: MP Ratio is irrelevant; <sup>**</sup>: Results
                from [<a href="#toc9">1</a>]
              </td>
            </tr>
          </tfoot>
          <tbody>
            <tr>
              <th class="tg-syo5">CTA</th>
              <th class="tg-syo5">0.2</th>
              <th class="tg-syo5">0.5</th>
              <th class="tg-syo5">0.8</th>
            </tr>
            <tr>
              <td class="tg-9wq8">
                <span style="color: #333; background-color: #fff"
                  >Single-Column<sup>*</sup></span
                >
              </td>
              <td class="tg-9wq8">
                <span style="color: #333; background-color: #fff">-</span>
              </td>
              <td class="tg-9wq8">
                <span style="color: #333; background-color: #fff">82.97</span>
              </td>
              <td class="tg-9wq8">
                <span style="color: #333; background-color: #fff">-</span>
              </td>
            </tr>
            <tr>
              <td class="tg-9wq8">
                <span style="color: #333; background-color: #fff"
                  >DODUO<sup>*,**</sup></span
                >
              </td>
              <td class="tg-9wq8">
                <span style="font-weight: 400; font-style: normal">-</span>
              </td>
              <td class="tg-9wq8">
                <span style="font-weight: 400; font-style: normal">84.82</span>
              </td>
              <td class="tg-9wq8">
                <span style="font-weight: 400; font-style: normal">-</span>
              </td>
            </tr>
            <tr>
              <td class="tg-9wq8">
                <span style="color: #333; background-color: #fff"
                  >TURL<sup>*,**</sup></span
                >
              </td>
              <td class="tg-9wq8">
                <span style="color: #333; background-color: #fff">-</span>
              </td>
              <td class="tg-9wq8">
                <span style="color: #333; background-color: #fff">78.96</span>
              </td>
              <td class="tg-9wq8">
                <span style="color: #333; background-color: #fff">-</span>
              </td>
            </tr>
            <tr>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >TaBERT</span
                >
              </td>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >92.14</span
                >
              </td>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >92.24</span
                >
              </td>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >91.60</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Col-TaBERT</span
                >
              </td>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >87.92</span
                >
              </td>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >88.40</span
                >
              </td>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >88.67</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Neighbor, WS=5</span
                >
              </td>
              <td class="tg-p91v">
                <span
                  style="
                    font-weight: 700;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >92.44</span
                >
              </td>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >92.14</span
                >
              </td>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >91.29</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Sum_Neighbor, WS=5</span
                >
              </td>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >90.97</span
                >
              </td>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >88.63</span
                >
              </td>
              <td class="tg-9wq8">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >85.82</span
                >
              </td>
              <tfoot>
                <tr></tr>
              </tfoot>
            </tr>
          </tbody>
        </table>

        <table class="tg">
          <caption>
            Table 1b: CPA Experiment results
          </caption>
          <thead>
            <tr>
              <th class="tg-mkpc"></th>
              <th class="tg-mkpc" colspan="3">
                <span style="background-color: #f0f0f0">MP Ratio</span>
              </th>
            </tr>
          </thead>
          <tfoot>
            <tr>
              <td colspan="4">
                <sup>*</sup>: MP Ratio is irrelevant; <sup>**</sup>: Results
                from [<a href="#toc9">1</a>]
              </td>
            </tr>
          </tfoot>
          <tbody>
            <tr>
              <th class="tg-syo5">CPA</th>
              <th class="tg-syo5">0.2</th>
              <th class="tg-syo5">0.5</th>
              <th class="tg-syo5">0.8</th>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Single-Column<sup>*</sup></span
                >
              </td>
              <td class="tg-zkss">-</td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >79.52</span
                >
              </td>
              <td class="tg-h2b0">-</td>
            </tr>

            <tr>
              <td class="tg-h2b0">DODUO<sup>*,**</sup></td>
              <td class="tg-h2b0">-</td>
              <td class="tg-h2b0">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >79.96</span
                >
              </td>
              <td class="tg-h2b0">-</td>
            </tr>
            <tr>
              <td class="tg-c3ow">TURL<sup>*,**</sup></td>
              <td class="tg-c3ow">-</td>
              <td class="tg-c3ow">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >72.93</span
                >
              </td>
              <td class="tg-c3ow">-</td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >TaBERT</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >83.09</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >83.68</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >82.49</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Col-TaBERT</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >82.79</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >83.22</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >82.38</span
                >
              </td>
            </tr>

            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Neighbor, WS=5</span
                >
              </td>
              <td class="tg-p91v">
                <span
                  style="
                    font-weight: 700;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >86.09</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >85.50</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >85.14</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Sum_Neighbor, WS=5</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >83.50</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >82.07</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >77.82</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >No-Main Neighbor, WS=5</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >85.88</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >85.29</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >84.87</span
                >
              </td>
            </tr>
          </tbody>
        </table>
        <table class="tg">
          <caption>
            Table 1c: Further Experiments for CPA
          </caption>
          <thead>
            <tr>
              <th class="tg-5vuh"></th>
              <th class="g-4akn">
                <span
                  style="
                    font-weight: 700;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Test Micro F1</span
                >
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-zkss">Subtable Model*</td>
              <td class="tg-zkss">83.20</td>
            </tr>
            <tr>
              <td class="tg-zkss">Two-Step Model*</td>
              <td class="tg-zkss">84.34</td>
            </tr>
            <tr>
              <td class="tg-zkss">Longformer*</td>
              <td class="tg-zkss">51.74</td>
            </tr>
          </tbody>
        </table>
      </div>

      <p>
        <b> SOTAB benchmark </b>
      </p>
      <p>
        Across both tasks, for all but one serializations implemented, we
        achieved significant improvement on Micro F1 against the single-column
        baseline serialization. For the CTA task, we are able to achieve a
        maximum increase of 7.62 point F1 score compared to the state-of-the-art
        DODUO model, with Neighboring Column Serialization of window size of 5
        and a MP Ratio of 0.2. Similar results are achieved by TaBERT and
        Neighoring Column Serialization indicating the importance of context
        ratio and certain structure for input sequence. The lower F1 score of
        Column-TaBERT compared to its counterpart of TaBERT, and like-wise for
        Neighboring Column with Summary, by roughly 3 points suggests the
        inability of Transformer's attention mechanism to identify significant
        positions in a input sequence.
      </p>
      <p>
        For the CPA task, different variances of Neighboring Column
        Serialization achieve 6 point higher F1 score than the existing methods.
        Once again, Neighboring Column Serialization of window size of 5 and MP
        Ratio of 0.2 achieves the highest F1 score. TaBERT variances score 2.5
        point lower F1 score indicating less suitability of row serialization
        for a column pair prediction. Once again, less structured serialization
        solutions achieve lower F1 scores (Column TaBERT and Neighboring Column
        with Summary). Lastly, only Neighboring Column with Summary with MP
        Ratio of 0.8 achieves lower F1 score than Single-Column. The MP Ratio of
        0.8 allocates 80% of the available token limit to the Main and Target
        Columns and only 20% to their neighbors, as explained earlier. Overall,
        our results highlight the importance of carefully selecting the
        appropriate serialization method to achieve optimal performance in table
        annotation tasks.
      </p>
      <p></p>

      <div style="text-align: center" class="tg-wrap">
        <table class="tg">
          <caption>
            Table 2a: CTA result for WikiTable
          </caption>
          <thead>
            <tr>
              <th class="tg-5vuh"><br /></th>
              <th class="tg-4akn">
                <span
                  style="
                    font-weight: 700;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Test Micro F1</span
                >
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Col-TaBERT</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >91.42</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >DODUO</span
                >
              </td>
              <td class="tg-p91v">
                <span
                  style="
                    font-weight: 700;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >92.45</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >TURL</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >88.86</span
                >
              </td>
            </tr>
          </tbody>
        </table>
        <table class="tg">
          <caption>
            Table 2b: CPA result for WikiTable
          </caption>
          <thead>
            <tr>
              <th class="tg-5vuh"><br /></th>
              <th class="tg-4akn">
                <span
                  style="
                    font-weight: 700;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Test Micro F1</span
                >
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >Col-TaBERT</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >92.85</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >DODUO</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >91.72</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >TURL</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >90.94</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >TaBERT</span
                >
              </td>
              <td class="tg-p91v">
                <span
                  style="
                    font-weight: 700;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >93.30</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >No-Main Neighbor</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >91.60</span
                >
              </td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>
        <b> Wikitables Dataset </b>
      </p>
      <p>
        In the CTA task, our Column-TaBERT Serialization achieved a comparable
        F1 score to the state-of-the-art DODUO, missing by only 1 point. This is
        a significant improvement over the TURL baseline, which we outperformed
        by 2.5 points. However, our results from SOTAB benchmark suggest that
        there may be even more room for improvement using other more performant
        serialization methods. For the CPA task, our TaBERT Serialization
        outperformed existing methods by 1.5 points in terms of F1 score. These
        results demonstrate that our serialization approaches can achieve
        comparable performance on different real-world datasets. Overall, our
        findings suggest that careful selection of serialization methods can
        significantly improve the performance of table annotation tasks.
      </p>
      <span id="toc6.2"></span>
      <h3>6.2 Ablation Study</h3>

      <div style="text-align: center" class="tg-wrap">
        <table class="tg">
          <caption>
            Table 3a: Preprocess and Augmentation test
          </caption>
          <thead>
            <tr>
              <th class="tg-4akn">
                <span
                  style="
                    font-weight: bold;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >Method</span
                >
              </th>
              <th class="tg-4akn">
                <span
                  style="
                    font-weight: bold;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >CTA with TaBERT</span
                ><br /><span
                  style="
                    font-weight: bold;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >MP Ratio=0.5</span
                >
              </th>
              <th class="tg-4akn">
                <span
                  style="
                    font-weight: bold;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                >
                  CPA with No-Main Neighbor</span
                ><br /><span
                  style="
                    font-weight: bold;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >MP Ratio=0.5</span
                >
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >TUTA</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >92.45</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >85.77</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >MEAN</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >92.05</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >85.70</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >MEDIAN</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >92.24</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >85.68</span
                >
              </td>
            </tr>
          </tbody>
        </table>
        <table class="tg">
          <caption>
            Table 3b: Window Size test for Neighboring Column
          </caption>
          <thead>
            <tr>
              <th class="tg-syo5">Window Size</th>
              <th class="tg-syo5">CTA</th>
              <th class="tg-syo5">CPA</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >1</span
                >
              </td>
              <td class="tg-3xi5">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >89.59</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >83.31</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >2</span
                >
              </td>
              <td class="tg-3xi5">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >91.20</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >84.71</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >3</span
                >
              </td>
              <td class="tg-3xi5">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >92.09</span
                >
              </td>
              <td class="tg-4akn">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >85.31</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >4</span
                >
              </td>
              <td class="tg-3xi5">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >92.21</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >85.86</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >5</span
                >
              </td>
              <td class="tg-3xi5">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >92.14</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >85.50</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >6</span
                >
              </td>
              <td class="tg-3xi5">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >91.80</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >85.79</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >7</span
                >
              </td>
              <td class="tg-3xi5">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >91.78</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                    background-color: transparent;
                  "
                  >85.81</span
                >
              </td>
            </tr>
          </tbody>
        </table>
        <table class="tg">
          <caption>
            Table ?: Augmentation method on single column serialization
          </caption>
          <thead>
            <tr>
              <th class="tg-mkpc">
                <span
                  style="font-style: normal; text-decoration: none; color: #000"
                  >Augmentation method</span
                >
              </th>
              <th class="tg-mkpc">
                <span
                  style="font-style: normal; text-decoration: none; color: #000"
                  >Test Micro F1</span
                >
              </th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >Baseline</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >77.95</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >Delete Random Cell</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >77.28</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >Replacewith Frequent Value</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >78.00</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >Shuffle Column Cell</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >77.29</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >Shuffle Column Cell Value</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >77.05</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >Swap Word</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >74.13</span
                >
              </td>
            </tr>
            <tr>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >Replace Word</span
                >
              </td>
              <td class="tg-zkss">
                <span
                  style="
                    font-weight: 400;
                    font-style: normal;
                    text-decoration: none;
                    color: #000;
                  "
                  >75.48</span
                >
              </td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>
        <b> Preprocess and Augmentation</b>
      </p>
      <p>
        Through our experiments, we found that preprocessing provides slight
        improvement on the performance of different serialization methods. This
        highlights the importance of providing structured input sequences to
        Transformer models and using more columns whenever possible.
        Furthermore, our initial experiments with data augmentation using
        single-column serialization indicate that, for large datasets like the
        SOTAB benchmark, the need for data augmentation may be limited.
      </p>

      <p>
        <b> Window Size</b>
      </p>

      <p>
        For the SOTAB benchmark, we identified that the suitable window size for
        Neighboring Column Serializations are window size of 4 - 6. This
        indicates that a complete table structure with relevant columns is a
        suitable input for Language models in table annotation tasks. Notably,
        we observed that the main difference between Neighboring Column
        Serialization and DODUO lies in the structure of the input sequence.
        Specifically, our approach places the target column at the front of the
        input sequence to focus on it, while DODUO takes the entire table as
        input.
      </p>

      <span id="toc6.3"></span>
      <h3>6.3 Error Analysis</h3>
      <p>
        To evaluate the performance of our best result from neighbor
        serialization with a window size of 2, we initially conducted statistic
        analysis on three different aspects: (i) schema type, (ii) data type,
        and (iii) specific challenges. Subsequently, we furthered look into the
        data and manually classified the errors.
      </p>
      <p>
        <b>(i) Schema Type: </b> The tables are distributed across 17 schema.org
        types and the tables do no include any metadata which means no table
        headers or cpations are available. We list the top 5 labels that reached
        the highest score in the overall test set and the top 5 labels that
        reached the lowest score for CTA in <i>Table 4a</i> and CPA in
        <i>Table 4b</i>. The performance of CTA and CPA varies across different
        schema types. <strong>MusicRecording</strong> is the only schema where
        both tasks perform well, while
        <strong>CreativeWork and Product</strong> are weak for both tasks.
        <strong>Recipe and Person</strong> are among the top 5 schemas for CTA,
        but are among the lowest 5 for CPA.
      </p>
      <div style="text-align: center" class="tg-wrap">
        <table class="tg">
          <caption>
            Table 4a: Schema Type result for CTA
          </caption>
          <thead>
            <tr>
              <th class="tg-ixdq" colspan="2">Top 5</th>
              <th class="tg-ixdq" colspan="2">Lowest 5</th>
            </tr>
            <tr>
              <th class="tg-mkpc">Label</th>
              <th class="tg-mkpc">Overall F1</th>
              <th class="tg-mkpc">Label</th>
              <th class="tg-mkpc">Overall F1</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Recipe</td>
              <td>96.23</td>
              <td>Product</td>
              <td>86.54</td>
            </tr>
            <tr>
              <td>Museum</td>
              <td>95.40</td>
              <td>Hotel</td>
              <td>86.05</td>
            </tr>
            <tr>
              <td>Event</td>
              <td>93.89</td>
              <td>JobPosting</td>
              <td>84.14</td>
            </tr>
            <tr>
              <td>Person</td>
              <td>93.07</td>
              <td>CreativeWork</td>
              <td>82.50</td>
            </tr>
            <tr>
              <td>MusicRecording</td>
              <td>92.59</td>
              <td>MusicAlbum</td>
              <td>74.07</td>
            </tr>
          </tbody>
        </table>

        <table class="tg">
          <caption>
            Table 4b: Schema Type result for CPA
          </caption>
          <thead>
            <tr>
              <th class="tg-ixdq" colspan="2">Top 5</th>
              <th class="tg-ixdq" colspan="2">Lowest 5</th>
            </tr>
            <tr>
              <th class="tg-mkpc">Label</th>
              <th class="tg-mkpc">Overall F1</th>
              <th class="tg-mkpc">Label</th>
              <th class="tg-mkpc">Overall F1</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Restaurant</td>
              <td>96.25</td>
              <td>SportsEvent</td>
              <td>84.50</td>
            </tr>
            <tr>
              <td>TVEpisode</td>
              <td>96.08</td>
              <td>Recipe</td>
              <td>82.25</td>
            </tr>
            <tr>
              <td>MusicRecording</td>
              <td>94.64</td>
              <td>Person</td>
              <td>81.24</td>
            </tr>
            <tr>
              <td>Place</td>
              <td>93.18</td>
              <td>CreativeWork</td>
              <td>76.36</td>
            </tr>
            <tr>
              <td>LocalBusiness</td>
              <td>90.04</td>
              <td>Product</td>
              <td>70.34</td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>
        <b>(ii) Data Type: </b> The columns are divided into 5 groups based on
        their data type: Boolean, Numeric, URL, short text and long text.
        Boolean columns contain only "yes" or "no" or "true" or "false" values,
        Numeric columns contain only numbers, and URL columns contain web
        addresses. All other columns are classified as text, and if the token in
        the value is less than five, it is considered short text, otherwise, it
        is long text. The results of each data type with micro-F1 score are
        summarized in Table 5 for CTA and CPA.
      </p>
      <div style="text-align: center" class="tg-wrap">
        <table class="tg">
          <caption>
            Table 5: Data Type Results for CTA & CPA
          </caption>
          <thead>
            <tr>
              <th></th>
              <th class="tg-ixdq">CTA</th>
              <th class="tg-ixdq">CPA</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-lboi">Boolean</td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>100
              </td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>85
              </td>
            </tr>
            <tr>
              <td class="tg-lboi">Numeric</td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>91.77
              </td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>75.06
              </td>
            </tr>
            <tr>
              <td class="tg-lboi">Long Text</td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>86.92
              </td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>88.17
              </td>
            </tr>
            <tr>
              <td class="tg-lboi">Short Text</td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>90.27
              </td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>82.52
              </td>
            </tr>
            <tr>
              <td class="tg-lboi">URL</td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>97.06
              </td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>94.71
              </td>
            </tr>
          </tbody>
        </table>
      </div>
      <p>
        <b>(iii) Specific Challenges: </b>The specific challgenges include:
        Missing Values, Value Format Heterogeneity, Corner Cases, and Random
        Columns which were all clearly defined in
        <a href="https://webdatacommons.org/structureddata/sotab/"
          >WDC Schema.org Table Annotation Benchmark (SOTAB)</a
        >[<a href="#toc9">1</a>]. The results are summarized in Table 6 for CTA
        and CPA.
      </p>
      <div style="text-align: center" class="tg-wrap">
        <table class="tg">
          <caption>
            Table 6: Specific Challenges Results for CTA & CPA
          </caption>
          <thead>
            <tr>
              <th></th>
              <th class="tg-ixdq">CTA</th>
              <th class="tg-ixdq">CPA</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-lboi">Test (Missing Values)</td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>90.60
              </td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>82.74
              </td>
            </tr>
            <tr>
              <td class="tg-lboi">Test (Format Heterogeneity)</td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>97.09
              </td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>86.55
              </td>
            </tr>
            <tr>
              <td class="tg-lboi">Test (Corner Cases)</td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>85.06
              </td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>73.48
              </td>
            </tr>
            <tr>
              <td class="tg-lboi">Test (Random Columns)</td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>90.89
              </td>
              <td class="tg-lboi">
                <span style="font-weight: 400; font-style: normal"></span>85.36
              </td>
            </tr>
          </tbody>
        </table>
      </div>

      <p>
        Following the statistical analysis of our results, we delved deeper into
        the data itself to investigate the root causes of the errors. To do
        this, we sampled errors in prediction by schema for both the CTA and CPA
        tasks. Specifically, we sampled 614 errors from a total of 1533
        observations for CTA, and 617 errors from 3853 observations for CPA. We
        manually checked these tables and classified the types of errors we
        found, which are listed in <i>Table 7</i>. And the distribution of error
        types in the samples are illustrated in the <i>figure X</i>.
      </p>
      <div style="text-align: center" class="tg-wrap">
        <table>
          <caption>
            Table 7: Error Types and Definitions
          </caption>
          <thead>
            <th>Observed Error Types</th>
            <th>Definition</th>
            <th>Example</th>
          </thead>
          <tbody>
            <tr>
              <td>Actual wrong label</td>
              <td>The label given in the table is obviously incorrect.</td>
              <td>10-digit-number is labeled as gtin8</td>
            </tr>
            <tr>
              <td>Bad prediction</td>
              <td>
                The data provided by the column and neighbor columns is
                sufficient but the prediction is incorrect.
              </td>
              <td>gtin12 is predicted as gtin14</td>
            </tr>
            <tr>
              <td>Schema related label</td>
              <td>
                The prediction correctly represents the data but does not match
                the associated schema.
              </td>
              <td>In Movie schema, Movie/name is predicted as Book/name</td>
            </tr>
            <tr>
              <td>Semantic label</td>
              <td>
                The prediction has the same data type or format as label, but
                the interpretation of the data was incorrect.
              </td>
              <td>FAXnumber is predicted as telephone number and vice versa</td>
            </tr>
            <tr>
              <td>Duplicate label</td>
              <td>
                Two columns in a table that have same values but are labeled
                differently, leading to data redundancy and potential confusion
                or inconsistency in the interpretation of the data. In this
                case, usually the wrong prediction is the label of the other
                column.
              </td>
              <td>
                columns with same value are labeled as Brand and Organization
                respectively
              </td>
            </tr>
            <tr>
              <td>Hierarchical label</td>
              <td>
                The prediction may represent a higher or lower level of
                abstraction than the label, but the semantic meaning is still
                understandable.
              </td>
              <td>
                <ul>
                  <li>Book/name is predicted as CreativeWork</li>
                  <li>Restaurant is predicted as LocalBusiness</li>
                </ul>
              </td>
            </tr>
            <tr>
              <td>Bad tables</td>
              <td>
                Approximately 80% of the values in the table are either empty
                strings, 'undefined', or contain erroneous data inputted by
                humans.
              </td>
              <td>Example given in <i>figure x</i>.</td>
            </tr>
            <tr>
              <td>Lack of information</td>
              <td>
                The data provided is insufficient in current and neighbor
                columns but contained in columns outside the windows.
              </td>
              <td>
                Example given in <i>figure y</i>. In CTA task, the target is to
                predict column 12, while the useful information is included in
                first few columns.
              </td>
            </tr>
          </tbody>
        </table>
      </div>
      <figure>
        <img
          src="images/example_bad_tables.png"
          alt="example_bad_tables"
          width="70%"
        />
        <figcaption>
          <b><a id="Fig1"></a>Figure 4: </b>Example of bad tables
        </figcaption>
      </figure>

      <figure>
        <img
          src="images/example_lack_info.png"
          alt="example_lack_info"
          width="70%"
        />
        <figcaption>
          <b><a id="Fig1"></a>Figure 5: </b>Example of Lack of information
        </figcaption>
      </figure>
      <figure>
        <img
          src="images/Percentage of Error Type in CTA sample.png"
          alt="percentage of CTA error type"
          width="45%"
        />
        <img
          src="images/Percentage of Error Type in CPA sample.png"
          alt="percentage of CPA error type"
          width="45%"
        />
        <figcaption>
          <b><a id=""></a>Figure 6:</b> CTA & CPA error types distribution in
          samples.
        </figcaption>
      </figure>
      <p>
        In addition to the absolute count of errors, we also aim to investigate
        the relative frequencies of errors and correct predictions, in order to
        gain a better understanding of the overall performance. Therefore, we
        seek to compare the ratio of incorrect predictions to correct
        predictions based on the same label.
      </p>
      <span class="math display">
        \[Relative Frequency(P,T) = \frac{P}{{T}}\]
      </span>
      <p>
        where <i>P</i> is counts of prediction for specific (label, prediction) pair, and <i>T</i> is counts of prediction of total pairs of the label. 
        For example, suppose we have a total of 100 predictions made for the 'ProductModel' label, 
        of which 20 were incorrectly predicted as 'IdentifierAT' and 60 were correctly predicted as 'ProductModel', 
        Therefore, the Relative Frequency of error prediction pair of ('ProductModel', 'IdentifierAT') is 0.2 and the Relative
        Frequency of correct prediction pair of ('ProductModel', 'ProductModel') is 0.6.
      </p>

      <span id="toc6"></span>
      <h2>6. Discussion</h2>
      <div class="tg-wrap">
        <table class="tg">
          <caption>
            Table ?: Statistics of WikiTable Dataset
          </caption>
          <thead>
            <tr>
              <th class="tg-mkpc"></th>
              <th class="tg-mkpc" colspan="3">CTA</th>
              <th class="tg-mkpc" colspan="3">CPA</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-mkpc"><br /></td>
              <td class="tg-mkpc">mean</td>
              <td class="tg-mkpc">median</td>
              <td class="tg-mkpc">mode</td>
              <td class="tg-mkpc">mean</td>
              <td class="tg-mkpc">median</td>
              <td class="tg-mkpc">mode</td>
            </tr>
            <tr>
              <td class="tg-mkpc">Train columns</td>
              <td class="tg-9wq8">1.58</td>
              <td class="tg-9wq8">1</td>
              <td class="tg-9wq8">1</td>
              <td class="tg-9wq8">2.18</td>
              <td class="tg-9wq8">2</td>
              <td class="tg-9wq8">2</td>
            </tr>
            <tr>
              <td class="tg-mkpc">Val columns</td>
              <td class="tg-9wq8">2.76</td>
              <td class="tg-9wq8">3</td>
              <td class="tg-9wq8">3</td>
              <td class="tg-9wq8">2.39</td>
              <td class="tg-9wq8">2</td>
              <td class="tg-9wq8">2</td>
            </tr>
            <tr>
              <td class="tg-mkpc">Test columns</td>
              <td class="tg-9wq8">2.73</td>
              <td class="tg-9wq8">3</td>
              <td class="tg-9wq8">3</td>
              <td class="tg-9wq8">2.41</td>
              <td class="tg-9wq8">2</td>
              <td class="tg-9wq8">2</td>
            </tr>
          </tbody>
        </table>
      </div>
      <p><b>WikiTable dataset</b></p>
      <p>
        In <i>Tables 2a and 2b</i>, we can see that the best serialization
        differs between the SOTAB and WikiTable datasets. One possible reason
        for this difference is that the WikiTable dataset contains more tables
        with few columns, such as some tables that only have 2 columns. This
        could cause the neighboring method to perform poorly and result in a
        lower F1 score on the test set.
      </p>
      <p><b>Column-TaBERT</b></p>
      <p>
        We had hypothesized that the Column-TaBERT method would be able to
        encode more information within the same limited number of tokens as
        TaBERT, and therefore produce better results. However, the results
        indicate that the column datatype performed worse than the cell
        datatype. This may be due to the fact that the structural design did not
        effectively enable the attention mechanism. In TaBERT, the model has one
        datatype token placed just before the cell value. In contrast,
        Column-TaBERT obtains the datatype only once and structures it as a
        normal cell value. Future experiments could explore ways to improve
        attention by altering this serialization design.
      </p>
      <span id="toc7"></span>
      <h2>7. Conclusion</h2>

      <p>
        To conclude our study, we have presented the Neighbor methods,we found
        that the performance of approach is limited by the context size and may
        not be as effective for tables with fewer columns. To address this
        limitation, future work could explore the use of LongFormer model to
        process longer text and potentially reduce the need for more columns in
        a horizontal direction. Additionally, we suggest investigating the use
        of contrastive learning to further enhance the performance on these
        tasks. With these future directions, we hope to continue improving table
        annotation and advancing the field towards more accurate and efficient
        models.
      </p>

      <span id="toc8"></span>
      <h2>8. References</h2>

      <p>
        <span id="toc9"></span>
        [1] K. Korini, R. Peeters, C. Bizer, SOTAB: The WDC Schema.org Table
        Annotation Benchmark, in: Semantic Web Challenge on Tabular Data to
        Knowledge Graph Matching (SemTab), CEUR-WS.org, 2022. <br />

        <span id="toc10"></span>
        [2] D. Ritze, O. Lehmberg, Y. Oulabi, C. Bizer, Profiling the Potential
        of Web Tables for Augmenting Cross-domain Knowledge Bases, in:
        Proceedings of the 25th International Conference on World Wide Web,
        2016, pp. 251â261.
        <br />

        <span id="toc11"></span>
        [3] E. Rahm, P. A. Bernstein, A survey of approaches to automatic schema
        matching, The VLDB Journal â The International Journal on Very Large
        Data Bases 10 (2001) 334â350. <br />

        <span id="toc12"></span>
        [4] X. Deng, H. Sun, A. Lees, Y. Wu, C. Yu, TURL: Table understanding
        through representation learning, Proceedings of the VLDB Endowment 14
        (2020) 307â319. <br />

        <span id="toc13"></span>
        [5] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, et al.,
        Attention is All you Need, in: Advances in Neural Information Processing
        Systems (NIPS 2017), volume 30, 2017. <br />

        <span id="toc14"></span>
        [6] M. Hulsebos, Ã. Demiralp, P. Groth, GitTables: A Large-Scale Corpus
        of Relational Tables, arXiv:2106.07258 (2022). <br />

        <span id="toc15"></span>
        [7] Suhara, Y., Li, J., Li, Y., Zhang, D., Demiralp, Ã. et al.
        âAnnotating columns with pre-trained language models.â In Proceedings of
        the 2022 International Conference on Management of Data, 2022, pp.
        1493â1503 <br />

        <span id="toc16"></span>
        [8] Wang, Z., Dong, H., Jia, R., Li, J., Fu, Z., Han, S., & Zhang, D.
        (2020). TUTA: Tree-based Transformers for Generally Structured Table
        Pre-training. Proceedings of the 27th ACM SIGKDD Conference on Knowledge
        Discovery & Data Mining. <br />

        <span id="toc17"></span>
        [9] Chen, J., JimÃ©nez-Ruiz, E., Horrocks, I., & Sutton, C. (2019).
        Learning Semantic Annotations for Tabular Data. ArXiv, abs/1906.00781.
        <br />

        <span id="toc18"></span>
        [10] Khurana, U., & Galhotra, S. (2021). Semantic Concept Annotation for
        Tabular Data. Proceedings of the 30th ACM International Conference on
        Information & Knowledge Management. <br />

        <span id="toc19"></span>
        [11] Zhang, D., Suhara, Y., Li, J., Hulsebos, M., Demiralp, C., & Tan,
        W.C. (2019). Sato: Contextual Semantic Type Detection in Tables. Proc.
        VLDB Endow., 13, 1835-1848. <br />

        <span id="toc20"></span>

        [12] Brugman, S. pandas-profiling: Exploratory Data Analysis for Python.
        https://github.com/pandas-profiling/ <br />

        <span id="toc21"></span>
        [13] Beltagy I, Peters ME, Cohan A. Longformer: The long-document
        transformer. arXiv preprint arXiv:2004.05150. 2020 Apr 10. <br />

        <span id="toc22"></span>
        [14] Devlin J, Chang MW, Lee K, Toutanova K. Bert: Pre-training of deep
        bidirectional transformers for language understanding. arXiv preprint
        arXiv:1810.04805. 2018 Oct 11.<br />

        <span id="toc23"></span>
        [15] Liu Y, Ott M, Goyal N, Du J, Joshi M, Chen D, Levy O, Lewis M,
        Zettlemoyer L, Stoyanov V. Roberta: A robustly optimized bert
        pretraining approach. arXiv preprint arXiv:1907.11692. 2019 Jul 26.<br />
      </p>

      <p>&nbsp;</p>

      <script type="text/javascript">
        $("#toc").toc({
          selectors: "h2", //elements to use as headings
          container: "#toccontent", //element to find all selectors in
          smoothScrolling: true, //enable or disable smooth scrolling on click
          prefix: "toc", //prefix for anchor tags and class names
          highlightOnScroll: true, //add class to heading that is currently in focus
          highlightOffset: 100, //offset to trigger the next headline
          anchorName: function (i, heading, prefix) {
            //custom function for anchor name
            return prefix + i;
          },
        });
        $('[id*="link_"]').each(function () {
          var element = $(this);
          element.click(function (e) {
            e.preventDefault();
            var id = element.attr("id").split("_")[1];
            element.parent().removeClass("show").addClass("no-show");
            $("#charts_" + id)
              .removeClass("no-show")
              .addClass("show");
          });
        });
        $('[id*="link_"]').each(function () {
          var element = $(this);
          element.click(function (e) {
            e.preventDefault();
            var id = element.attr("id").split("_")[1];
            element.parent().removeClass("show").addClass("no-show");
            $("#charts_" + id)
              .removeClass("no-show")
              .addClass("show");
          });
        });
        $('[id*="colapse_"]').each(function () {
          var element = $(this);
          element.click(function (e) {
            e.preventDefault();
            var id = element.attr("id").split("_")[1];
            element.parent().removeClass("show").addClass("no-show");
            $("#intro_" + id)
              .removeClass("no-show")
              .addClass("show");
          });
        });
        document.getElementById("defaultOpen").click();
      </script>
    </div>
  </body>
</html>
